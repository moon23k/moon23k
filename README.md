### Hi there 👋

<!--
**moon23k/moon23k** is a ✨ _special_ ✨ repository because its `README.md` (this file) appears on your GitHub profile.

Here are some ideas to get you started:

- 🔭 I’m currently working on ...
- 🌱 I’m currently learning ...
- 👯 I’m looking to collaborate on ...
- 🤔 I’m looking for help with ...
- 💬 Ask me about ...
- 📫 How to reach me: ...
- 😄 Pronouns: ...
- ⚡ Fun fact: ...
-->




<a href="" target="_blank"><img src="https://img.shields.io/badge/뱃지레이블-배경색?style=뱃지모양&logo=로고&logoColor=로고색상"/></a>



### Projects
| Name | Desc | Models |
|------|------|--------|
| NMT_Basic | 대규모 사전학습이 없는, 비교적 가벼운 모델을 통한 Machine Translation의 구현 및 비교  | Seq2Seq, Seq2Seq with Attention Mechanism, Transformer  |
| NMT_BERT | NMT Task에 BERT 모델들을 반영히고, Parameter Sharing을 반영하는 Light Version과 일반 Version을 비교해봅니다. | BERT, AlBERT, Distil_BERT, RoBERTa  |
| NMT_KoBERT | 앞선 NMT_BERT에서의 로직과 동일하지만, 한국어 데이터를 바탕으로 KoBERT 및 다언어를 지원하는 BERT Bilingual 모델을 비교해봅니다. Parameter Sharing을 반영하는 Light Version과 일반 Version을 비교해봅니다. | KoBERT, BERT_multilingual  |
| NMT_Transformers | Transformer기반의 세가지 구조를 구현 및 NMT Task에서의 성능을 비교해봅니다. | Transformer, Universal Transformer, Transformer_XL |
| Characteristic ChatBot | 사람처럼 성격을 지니는 챗봇을 구현해봅니다 |  |
| Multi-Turn ChatBot | Single Turn의 대화방식을 넘어 Multi Turn에서 자연스러운 대화를 이어갈 수 있는 ChatBot을 구현해봅니다 |  |
| ChatBot with Reinforcement Learning | 강화학습을 사용해서 전체적으로 자연스러운 대화를 만들수 있도록 모델의 학습과정을 고도화해봅니다. |  |


<br>

## Github Stats  
<table><tr><td valign="top" width="50%">

<img src="https://github-readme-stats.vercel.app/api?username=moon23k&show_icons=true&count_private=true&hide_border=true" align="left" style="width: 100%" />

</td><td valign="top" width="50%">
  
<img src="https://github-readme-stats.vercel.app/api/top-langs/?username=moon23k&hide_border=true&layout=compact" align="left" style="width: 100%" />

</td></tr></table>  
